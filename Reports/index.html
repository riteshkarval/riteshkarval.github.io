<!DOCTYPE html>
<html>
    <head>
        <title>Reports</title>
        <link href="https://fonts.googleapis.com/css?family=Raleway|Yesteryear" rel="stylesheet">
        <link rel="stylesheet" type="text/css" href="../css/bootswatch.css"/>
        <link rel="stylesheet" type="text/css" href="../css/style.css"/>
        <link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css"/>

    </head>
    <style>
            table, td, th {  
              border: 1px solid #ddd;
              text-align: left;
            }
            
            table {
              border-collapse: collapse;
              width: 70%;
            }
            
            th, td {
              padding: 15px;
            }
    </style>

    <body>
        <div class="container">
            <header>
                <nav class="navbar navbar-default navbar-fixed-top">
                    <div class="container">
                        
                        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-2">
                        <ul class="nav navbar-nav">
                            <li class="active"><a class="navbar-brand" href="https://riteshkarval.github.io/"><i class="fa fa-home" aria-hidden="true"></i>&nbsp;Home</a></li>
                            <li class=""><a id="educationAnchor" href="https://riteshkarval.github.io/#educationDiv"><i class="fa fa-briefcase" aria-hidden="true"></i>&nbsp;Education</a></li>
                            <li><a id="publicationsAnchor" href="https://riteshkarval.github.io/#publicationsDiv"><i class="fa fa-certificate" aria-hidden="true"></i> Publications</a></li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Reports <span class="caret"></span></a>
                                <ul class="dropdown-menu" role="menu">
                                    <li><a href="https://riteshkarval.github.io/Reports/">Reports</a></li>
                                </ul>
                                </ul>
                            </li>
                        </ul>
                        
                        </div>
                    </div>
                </nav>
            </header>

            <main>

                <!-- Copy this block to add new report
                    <button class="collapsible">
                            <h4 class="heading">SRM </h4>09/07/19
                    </button>
                    <div class="content">
                        text/content to add
                    </div>
                -->

            
                <button class="collapsible">
                        <h4 class="heading">SRM Report</h4>(09/07/19)
                </button>
                <div class="content">
                    <h3 class="heading">Work done this week</h3>
                    <ol>
                        <li><h4 class="heading">Implemented HWNet-V1 in TensorFlow:</h4>Collected the IIIT-HWS dataset and training the network on 10K vocabulary.</li>
                        <li><h4 class="heading">Online handwritten text recognition:</h4>In order to improve the implemented Online-HTR, currently reading the literature to understand the Online handwriting
                                                and it's processing.</li>
                        <li><h4 class="heading">Bézier curve: </h4>Lerning the Bézier curve to implement Google online-HTR.</li>
                        
                    </ol>
                </div>

            <!--Next Report -->

                <p></p>
               <button class="collapsible"><h4 class="heading">"A novel approach to on-line handwriting recognition based on bidirectional 
                   long short-term memory networks"</h4>(29/06/19)</button> 
               <div class="content">
                    <br/>
                    <p>
                        This implementation address the recognition of handwritten text written on a touch eanabled devices.
                        The digital touch enabled devices captures the handwritten input in form of points, which makes it the problem of sequence of points to
                        the sequence of characters generation. Each input x is a sequence points features(described in section 2.1),
                        and output y is a sequence of characters and the maximum output sequence is 36 chars. RNNs are cabable of learning a sequence to sequence mappinng, 
                        Bi-LSTMs have been used to design the model(fig 1) by the authors. Paper <a href="http://www.i6.in.tum.de/Main/Publications/Liwicki2007a.pdf" target="_blank"> link</a>. 

                        
                    </p>
                    <h3 class="heading">1: Dataset:</h3>
                    <p>
                        To train the online handwriting recognition system IAM-on-DB has been used which has writing samples
                        from 221 writers. The dataset has 13,049 lines of text which has 86,272 word instances and 
                        forms a vocabulary of length 11,059. 
                    </p>
                    <p>
                        More details about the IAM-On-DB can be read <a href="https://ieeexplore.ieee.org/document/1575685", target="_blank">here</a>. 
                            The dataset is further divided into four sets(Training set, validation set, test set 1, test set 2) 
                            in a ratio of 6:2:1:1.
                        </p><br/>
                        
                    <h3 class="heading">2: Model:</h3>
                    <h3 class='heading'>2.1: Input Features</h3>
                    <h5 class="heading">Pen-up/pen-down, Hat-feature, Speed, X-coordinate, Y-coordinate, Writing direction, Curvature,
                        Vicinity slope, Vicinity curliness, Vicinity linearity.</h5>
                    <p>
                            The model takes a matrix of size 1942x10 as input(1942 is maximum timesteps for a line and 10 is the length of feature vector). The model has two layers of Bi-directional LSTM having 64 cells in both 
                            forward and backward direction. The output of second BLSTM layer has been feeded into a dense layer of size 64(63 characters and one CTC blank) having a softmax activation.
                            The model has been has been shown in Fig-1 below.
                    </p>
                    <p>
                            The network weights were initialized with a Gaussian distribution of mean 0 and std. deviation 0.1. The network was trained with online gradient descent, using a 
                            learning rate of 1e−4 and a momentum of 0.9 with <a href="https://towardsdatascience.com/intuitively-understanding-connectionist-temporal-classification-3797e43a86c">CTC loss</a>.
                    </p>
                    <h3><b>2.2: Decoding</b></h3>
                    <p>
                        The output of the softmax layer is a sequence of T time steps of (C + 1) classes that were decoded using <a href="https://towardsdatascience.com/beam-search-decoding-in-ctc-trained-neural-networks-5a889a3d85a7">
                                CTC decoding</a>.
                    </p>
                    <center>
                    <table style="width:100%">
                        <tr>
                            <td>
                                <center>
                                    <figure>
                                            <img src="Grave_2007/Grave_2007.png" alt="Trulli" style="width:80%">
                                            <figcaption>Fig.1 - Bi-LSTM HTR model.</figcaption>
                                    </figure>
                                </center>
                            </td>
                            <td>
                                <center>
                                    <figure>
                                            <img src="Grave_2007/Grave_training_graph.png" alt="Trulli" style="width:80%">
                                            <figcaption>Fig.2 - Training and validation error graph.</figcaption>
                                    </figure>
                                </center>
                            </td>
                        </tr>
                    </table>
                    </center>
                    <h2> <b>3: Results:</b> </h2>
                    <p>
                            <t>Training was stopped when performance ceased to improve on the validation set(96 epochs in our case).  
                            After training the model was evaluated on the Test dataset, the model had performed with a character error rate of ~35%. The training and validation has been shown in Fig-2 above.
                    </p>
                    <h3><b>3.1: Comparision of CER with recent works</b></h3>
                    <p>
                        Table-1 shows the comparison of character error rate on  on IAM-On-DB of this implementation with the recent state-of-art works.
                    </p>
                    <center>
                            <table id='table_caption'>
                                    <caption>Table:1 Comparision of character error rate on IAM-On-DB with recent works</caption>
                                <tr>
                                    <th>System</th>
                                    <th>CER[%]</th>
                                </tr>
                                <tr>
                                    <td>Graves et al. BLSTM - 2007</td>
                                    <td>~15</td>
                                </tr>
                                <tr>
                                    <td>Graves et al. BLSTM - 2009</td>
                                    <td>11.5</td>
                                </tr>
                                <tr>
                                    <td>Frinken et al. BLSTM - 2015</td>
                                    <td>12.3</td>
                                </tr>
                                <tr>
                                    <td>Keysers et al. BLSTM - 2017</td>
                                    <td>8.8</td>
                                </tr>
                                <tr>
                                    <td>Carbune, Victor, et al. - 2019</td>
                                    <td>4.02</td>
                                </tr>
                                <tr>
                                    <td>this implementation</td>
                                    <td>34.5</td>
                                </tr>
                            </table>
                    </center>

                    <h3> <b>3.2: Model output samples:</b> </h3>
                    <p>
                        In Table-2 the sample outputs of the network has been shown. The input samples were taken randomly from the test set. 
                    </p>
                    <center>
                            <table id='table_caption'>
                                    <caption>Table:2 Model output comparison with the ground truth</caption>
                                <tr>
                                    <th>Ground truth</th>
                                    <th>Model Output</th>
                                </tr>
                                <tr>
                                    <td>and now was a digniflied discreet</td>
                                    <td>and how wal d aguitud  rrdereet</td>
                                </tr>
                                <tr>
                                    <td>hand After all he reflected</td>
                                    <td>hand A5ter all he reflected</td>
                                </tr>
                                <tr>
                                    <td>with a deadly finality</td>
                                    <td>htth odedar thodty</td>
                                </tr>
                                <tr>
                                    <td>had sent a letter to Mr Kennedy saying</td>
                                    <td>had seut altertor Ruhedy say in</td>
                                </tr>
                            </table>
                    </center>
                    
                <h3> <b>4: References:</b> </h3>
                <ol>
                    <li>Liwicki, Marcus, et al. "A novel approach to on-line handwriting recognition based on bidirectional long short-term memory networks." Proceedings of the 9th International Conference on Document Analysis and Recognition, ICDAR 2007. 2007.</li>	
                    <li>Frinken, Volkmar, and Seiichi Uchida. "Deep BLSTM neural networks for unconstrained continuous handwritten text recognition." 2015 13th International Conference on Document Analysis and Recognition (ICDAR). IEEE, 2015.</li>
                    <li>Graves, Alex, et al. "A novel connectionist system for unconstrained handwriting recognition." IEEE transactions on pattern analysis and machine intelligence 31.5 (2008): 855-868.</li>
                    <li>Keysers, Daniel, et al. "Multi-language online handwriting recognition." IEEE transactions on pattern analysis and machine intelligence 39.6 (2016): 1180-1194.</li>
                    <li>Carbune, Victor, et al. "Fast Multi-language LSTM-based Online Handwriting Recognition." arXiv preprint arXiv:1902.10525 (2019).</li>
                    <li>Graves, Alex, et al. "Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks." Proceedings of the 23rd international conference on Machine learning. ACM, 2006.</li>
                </ol>  
            </div>                
                
            </main>

            <footer>
                
            </footer>
        </div>

        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
        <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
        
        <script src="js/script.js"></script>
        <script>
            var coll = document.getElementsByClassName("collapsible");
            var i;

            for (i = 0; i < coll.length; i++) {
            coll[i].addEventListener("click", function() {
                this.classList.toggle("active");
                var content = this.nextElementSibling;
                if (content.style.maxHeight){
                content.style.maxHeight = null;
                } else {
                content.style.maxHeight = content.scrollHeight + "px";
                } 
            });
            }
        </script>
    </body>
</html>