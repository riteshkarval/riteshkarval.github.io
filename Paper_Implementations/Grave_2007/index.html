<!DOCTYPE html>
<html>
    <head>
        <title>A novel approach to on-line handwriting recognition based on bidirectional long short-term memory networks</title>
        <link href="https://fonts.googleapis.com/css?family=Raleway|Yesteryear" rel="stylesheet">
        <link rel="stylesheet" type="text/css" href="../../css/bootswatch.css"/>
        <link rel="stylesheet" type="text/css" href="../../css/style.css"/>
        <link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css"/>
    </head>
    <style>
            table, td, th {  
              border: 1px solid #ddd;
              text-align: left;
            }
            
            table {
              border-collapse: collapse;
              width: 70%;
            }
            
            th, td {
              padding: 15px;
            }
    </style>

    <body>
        <div class="container">
            <header>
                <nav class="navbar navbar-default navbar-fixed-top">
                    <div class="container">
                        
                        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-2">
                        <ul class="nav navbar-nav">
                            <li class="active"><a class="navbar-brand" href="https://riteshkarval.github.io/"><i class="fa fa-home" aria-hidden="true"></i>&nbsp;Home</a></li>
                            <li class=""><a id="educationAnchor" href="https://riteshkarval.github.io/#educationDiv"><i class="fa fa-briefcase" aria-hidden="true"></i>&nbsp;Education</a></li>
                            <li><a id="publicationsAnchor" href="https://riteshkarval.github.io/#publicationsDiv"><i class="fa fa-certificate" aria-hidden="true"></i> Publications</a></li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Reports <span class="caret"></span></a>
                                <ul class="dropdown-menu" role="menu">
                                    <li><a href="https://riteshkarval.github.io/Paper_Implementations/", target="_blank">Paper Implementations</a></li>
                                    <li class="divider"></li>
                                    <li><a href="https://riteshkarval.github.io/SRM/">SRM Reports</a></li>
                                </ul>
                            </li>
                        </ul>
                        
                        </div>
                    </div>
                </nav>
            </header>

            <main>
               <div>
                   <h1><b>“A novel approach to on-line handwriting recognition based on bidirectional long short-term memory 
                        networks” by Alex Graves et al.</b>
                   </h1>
                </div>
                <div class="row">
                     <p><br/> 
                        Due to increasing number of people in emerging markets are obtaining access to computing devices, 
                        many exclusively using mobile devices with touchscreens online handwriting recognition has recently been 
                        gaining importance. Many of these users have native languages and scripts that are not as easily typed as English, 
                        e.g. due to the size of the alphabet or the use of grapheme clusters which make it difficult to design an intuitive keyboard layout. 
                        And nowadays more and more large mobile devices with styluses are becoming available, such as the iPad Pro , Microsoft Surface devices , 
                        and Chromebooks with styluses. 
                    </p><br/>
                    <p>
                        Here the implementation of “A novel approach to on-line handwriting recognition based on bidirectional long short-term memory 
                        networks” and the obtained results has been discussed. In the following sections dataset, model architecture and results has been discussed. 
                    </p>
                </div>
                <div class="row">
                    <div>
                    <h2> <b>1: Dataset:</b> </h2>
                    <p>
                        To train the online handwriting recognition system IAM-on-DB has been used which has writing samples
                        from 221 writers. The dataset has 13,049 lines of text which has 86,272 word instances and 
                        forms a vocabulary of length 11,059. 
                    </p><br/>
                    <center>
                    <figure>
                      <img src="IAM_recording.jpeg" alt="Trulli" style="width:30%">
                      <figcaption>Fig.1 - Illustration of IAM-on-DB data recording.</figcaption>
                    </figure> <br/>
                    </center>
                    <p>
                        The eBeam interface2 is used for recording the handwriting. It allows the user to 
                        write on a whiteboard with a normal pen in a special casing, which sends infrared signals to 
                        a triangular receiver mounted in one of the corners of the whiteboard. The acquisition interface 
                        outputs a sequence of (x,y)-coordinates representing the location of the tip of the pen together 
                        with a time stamp for each location. The frame rate of the recordings varies from 30 to 70 frames 
                        per second. 
                    </p>
                    <p>
                        The IAM online handwriting data can be downloaded from <a href="http://www.fki.inf.unibe.ch/databases/iam-on-line-handwriting-database" target="_blanl">here</a>
                    </p>
                    </div>
                        <p>
                            The dataset is further divided into four sets(Training set, validation set, test set 1, test set 2) 
                            in a ratio of 6:2:1:1.
                        </p>
                </div>    
                <div class="row">
                    <h2> <b>2: Model Architecture:</b> </h2>
                    <p>
                            The model takes a matrix of size 1942x10 as input(1942 is maximum timesteps for a line and 10 is the length of feature vector). The model has two layers of Bi-directional LSTM having the same no of cells in both 
                            forward and backward direction. Each layer of BLSTM has 64 cells. The output of second BLSTM layer 
                            has been feeded into a dense layer of size 64(63 characters and one CTC blank) having a softmax activation. To measure the network performance CTC loss has been used.
                    </p><br/>
                    <p>
                            The network weights were initialized with a Gaussian distribution of mean 0 and std. deviation 0.1. The network was trained with online gradient descent with momentum, using a 
                            learning rate of 1e−4 and a momentum of 0.9. 
                    </p>
                    <h3><b>2.1: Input features</b></h3>
                    <ol>
                        <li><b>Pen-up/pen-down:</b> a boolean variable indicating whether or not the pen-tip touches the board.</li>
                        <li><b>Hat-feature:</b> this feature indicates if a delayed stroke was removed at the considered horizontal position.</li>
                        <li><b>Speed:</b> the velocity at point pi is computed before resampling and then interpolated.</li>
                        <li><b>X-coordinate:</b> the x-position of point pi is taken after high-pass filtering (subtracting a moving average)</li>
                        <li><b>Y-coordinate:</b> the vertical position after normalisation</li>
                        <li><b>Writing direction:</b> the cosine and sine of the angle between the line segment starting at pi and the x-axis.</li>
                        <li><b>Curvature:</b> the cosine and sine of the angle between the lines to the previous and the next point.</li>
                        <li><b>Vicinity slope:</b> cosine and sine of the angle α(t) of the straight line from the first to the last vicinity point.</li>
                        <li><b>Vicinity curliness:</b> the length of the trajectory in the vicinity divided by max(∆x(t), ∆y(t)).</li>
                        <li><b>Vicinity linearity:</b> the average square distance d 2 of each point in the vicinity to the straight line from the first to the last vicinity point.</li>
                        </ol> <br/>
                    <center>
                        <figure>
                            <img src="Grave_2007.png" alt="Trulli" style="width:40%">
                            <figcaption>Fig.2 - BLSTM model for online HTR.</figcaption>
                        </figure>
                    </center>
                    <h3><b>2.2: Decoding</b></h3>
                    <p>
                        The output of the softmax layer is a sequence of T time steps of (C + 1) classes that were decoded using CTC decoding.
                    </p>
                </div>
                <div class="row">
                        <h2> <b>3: Results:</b> </h2>
                        <p>
                                <t>Training was stopped when performance ceased to improve on the validation set(96 epochs in our case). Reduction in loss can be seen in Fig:2.  
                                After training the model was evaluated on the Test dataset, the model performs with a character error rate of ~35%.
                        </p>
                        <center>
                        <figure>
                                <img src="Grave_training_graph.png" alt="Trulli" style="width:40%">
                                <figcaption>Fig.3 - Training graph of HTR model.</figcaption>
                        </figure>
                        </center>
                        <h3><b>3.1: Comparision with recent works</b></h3>
                        <p>
                            After training the model for 96, character error rate of ~35% has been achieved. Beyond 96 epochs the model find to be overfit on the training
                            data as the training was decreasing but validation loss was increasing. In 2019 Goolge has reported the lowest character error rate on IAM-On-DB i.e.
                            4.02 and introduced the importance of Bezier Curve in online handwriting recognition. Below is the comparison of this implementation with the recent 
                            benchmarks on IAM-On-DB. 
                        </p>
                        <center>
                                <table>
                                    <tr>
                                        <th>System</th>
                                        <th>CER[%]</th>
                                    </tr>
                                    <tr>
                                        <td>Graves et al. BLSTM - 2007</td>
                                        <td>~15</td>
                                    </tr>
                                    <tr>
                                        <td>Graves et al. BLSTM - 2009</td>
                                        <td>11.5</td>
                                    </tr>
                                    <tr>
                                        <td>Frinken et al. BLSTM - 2015</td>
                                        <td>12.3</td>
                                    </tr>
                                    <tr>
                                        <td>Keysers et al. BLSTM - 2017</td>
                                        <td>8.8</td>
                                    </tr>
                                    <tr>
                                        <td>Carbune, Victor, et al. - 2019</td>
                                        <td>4.02</td>
                                    </tr>
                                    <tr>
                                        <td>this implementation</td>
                                        <td>34.5</td>
                                    </tr>
                                </table>
                        </center>

                        <h3> <b>3.2: Model output samples:</b> </h3>
                        <p>
                            After training the model was tested on the test dataset, the model's softmax output was feeded inito CTC decoder for decoding. Here are some 
                            predictions made by model on the test dataset. 
                        </p>
                        <center>
                                <table>
                                    <tr>
                                        <th>Ground truth</th>
                                        <th>Model Output</th>
                                    </tr>
                                    <tr>
                                        <td>and now was a digniflied discreet</td>
                                        <td>and how wal d aguitud  rrdereet</td>
                                    </tr>
                                    <tr>
                                        <td>hand After all he reflected</td>
                                        <td>hand A5ter all he reflected</td>
                                    </tr>
                                    <tr>
                                        <td>with a deadly finality</td>
                                        <td>htth odedar thodty</td>
                                    </tr>
                                    <tr>
                                        <td>had sent a letter to Mr Kennedy saying</td>
                                        <td>had seut altertor Ruhedy say in</td>
                                    </tr>
                                </table>
                        </center>
                </div>
                <div class="row">
                    <h2> <b>4: Conclusion and future work:</b> </h2>
                    <p>
                        Here an attempt to reproduce the results of "A novel approach to on-line handwriting recognition based on bidirectional long short-term memory networks."
                        has been taken. However, the lowest CER acheived from this implementation is still too far from the original work. This may be happen due to the model 
                        got stuck into the local minima. Training the model for further more epochs may give the better performance as 96 epochs is still a small number for training 
                        a online handwriting recognition model. 
                    </p>
                    <p>
                        Further improvements can be mode by adding a character and wrod level language model to the system. As described in "Fast Multi-language LSTM-based Online Handwriting Recognition."
                        Bezier curve will also help to improve the recognition. 
                    </p>
                </div>
                <div class="row">
                        <h2> <b>5: References:</b> </h2>
                        <ol>
                            <li>Liwicki, Marcus, et al. "A novel approach to on-line handwriting recognition based on bidirectional long short-term memory networks." Proceedings of the 9th International Conference on Document Analysis and Recognition, ICDAR 2007. 2007.</li>	
                            <li>Frinken, Volkmar, and Seiichi Uchida. "Deep BLSTM neural networks for unconstrained continuous handwritten text recognition." 2015 13th International Conference on Document Analysis and Recognition (ICDAR). IEEE, 2015.</li>
                            <li>Graves, Alex, et al. "A novel connectionist system for unconstrained handwriting recognition." IEEE transactions on pattern analysis and machine intelligence 31.5 (2008): 855-868.</li>
                            <li>Keysers, Daniel, et al. "Multi-language online handwriting recognition." IEEE transactions on pattern analysis and machine intelligence 39.6 (2016): 1180-1194.</li>
                            <li>Carbune, Victor, et al. "Fast Multi-language LSTM-based Online Handwriting Recognition." arXiv preprint arXiv:1902.10525 (2019).</li>
                            <li>Graves, Alex, et al. "Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks." Proceedings of the 23rd international conference on Machine learning. ACM, 2006.</li>
                        </ol>  
                              
                </div>
            </main>

            <footer>
                <div class="card">
                    <p><a href="https://riteshkarval.github.io/Paper_Implementations/">Old posts</a></p>
                </div>
            </footer>
        </div>

        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
        <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
        
        <script src="js/script.js"></script>
    </body>
</html>
